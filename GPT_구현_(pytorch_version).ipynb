{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YKpnANVbIu92",
        "8WfV5A68noA7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKpnANVbIu92"
      },
      "source": [
        "# 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RNWs1wj0tv",
        "outputId": "3f37eb01-8330-40c1-e4b2-f9daa63c69e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Korpora in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.8/dist-packages (from Korpora) (4.64.1)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from Korpora) (1.2.0)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.8/dist-packages (from Korpora) (0.6)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from Korpora) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from Korpora) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->Korpora) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->Korpora) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->Korpora) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->Korpora) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.8/dist-packages (0.13.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.1.97)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.8/dist-packages (0.13.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install Korpora\n",
        "! pip install tokenizers\n",
        "! pip install transformers[sentencepiece]\n",
        "! pip install tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXzW3ei9SLJQ"
      },
      "source": [
        "# dataset download(뉴스기사)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZC2yfeMXUoH",
        "outputId": "20432f78-1953-4076-82a4-fab431a7e814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "# 정답 추출\n",
        "news_json1 = open('/content/drive/MyDrive/Colab Notebooks/데이터사이언스 특론/term project/017.뉴스 기사 기계독해 데이터/01.데이터/1.Training/라벨링데이터/news_QnA/TL_span_extraction.json', encoding = 'utf-8')\n",
        "\n",
        "news_dict = json.load(news_json1)"
      ],
      "metadata": {
        "id": "2vCq5Bcqngrc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data preprocessing"
      ],
      "metadata": {
        "id": "G0aFdXJtrTtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = []\n",
        "for data in news_dict['data']:\n",
        "  context = data['paragraphs'][0]['context']\n",
        "  context_list = context.replace('\\n','').split('.')\n",
        "  sentence_list.extend(context_list)"
      ],
      "metadata": {
        "id": "9pcQdg_InnqF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "df['sentence'] = sentence_list\n",
        "\n",
        "def strip(x):\n",
        "  return x.strip()\n",
        "\n",
        "df['sentence'] = df.sentence.apply(strip)\n",
        "df = df[:100000]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s8wHxXGUnnsb",
        "outputId": "a0e8c002-e05c-4dfa-f58a-84239dd19034"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence\n",
              "0       익산시 서부권역 다목적 체육관이 내달 개관을 앞두고 막바지 개관 준비가 한창이다\n",
              "1  시에 따르면 시민들의 건강증진과 삶의 질 향상을 위한 생활체육 인프라 확충 등을 위...\n",
              "2  전문 체육시설인 서부권역 다목적 체육관은 지하 1층과 지상 3층, 연면적 4719㎡...\n",
              "3  수영장 6개 레인과 어린이풀장, 다목적실(에어로빅, 요가 등), 체력단련실, 어르신...\n",
              "4                               첫 번째로 개관되는 시설은 헬스장이다"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34bcdfc0-4cb1-4918-82d1-f154f339179f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>익산시 서부권역 다목적 체육관이 내달 개관을 앞두고 막바지 개관 준비가 한창이다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>시에 따르면 시민들의 건강증진과 삶의 질 향상을 위한 생활체육 인프라 확충 등을 위...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>전문 체육시설인 서부권역 다목적 체육관은 지하 1층과 지상 3층, 연면적 4719㎡...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>수영장 6개 레인과 어린이풀장, 다목적실(에어로빅, 요가 등), 체력단련실, 어르신...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>첫 번째로 개관되는 시설은 헬스장이다</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34bcdfc0-4cb1-4918-82d1-f154f339179f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34bcdfc0-4cb1-4918-82d1-f154f339179f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34bcdfc0-4cb1-4918-82d1-f154f339179f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Waw2kcsVVOle"
      },
      "source": [
        "## BPE tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/논문구현/news.txt', 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(df['sentence']))"
      ],
      "metadata": {
        "id": "nm5c8FjTNOxO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    add_prefix_space = True,\n",
        "    lowercase = False)"
      ],
      "metadata": {
        "id": "aJIWbmDcLX9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = '/content/drive/MyDrive/Colab Notebooks/논문구현/news.txt'\n",
        "vocab_size = 40000\n",
        "min_frequency = 5\n",
        "\n",
        "tokenizer.train(\n",
        "    files = data_file,\n",
        "    vocab_size = vocab_size,\n",
        "    min_frequency = min_frequency)"
      ],
      "metadata": {
        "id": "F84eqErfLX_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.add_special_tokens(['[EOS]', '[BOS]', '[PAD]'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdbqxJm7ljI9",
        "outputId": "da1e4e5a-d968-4a29-d640-5438e3604b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_model('/content/drive/MyDrive/Colab Notebooks/논문구현/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG6GrTu3huLI",
        "outputId": "8a00ebfc-2087-4976-8d5a-2839363f9c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/논문구현/vocab.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/논문구현/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "# 불러오기\n",
        "vocab = '/content/drive/MyDrive/Colab Notebooks/논문구현/vocab.json'\n",
        "merges = '/content/drive/MyDrive/Colab Notebooks/논문구현/merges.txt'\n",
        "\n",
        "bpe_tokenizer = ByteLevelBPETokenizer(\n",
        "    vocab = vocab,\n",
        "    merges = merges)"
      ],
      "metadata": {
        "id": "IhumASTCiGt-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bpe_tokenizer.add_special_tokens(['[EOS]', '[BOS]', '[PAD]'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBSuCNB3jAM8",
        "outputId": "23dcb0d0-2b6b-442d-bd15-def7d5e4fd6f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "F3lHnexJjJID"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rDyibQ8WQjcJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "de6d9915-f946-4bec-95b5-a0791663c7d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  [BOS] 익산시 서부권역 다목적 체육관이 내달 개관을 앞두고 막바지 개관 준비가 ...   \n",
              "1  [BOS] 시에 따르면 시민들의 건강증진과 삶의 질 향상을 위한 생활체육 인프라 확...   \n",
              "2  [BOS] 전문 체육시설인 서부권역 다목적 체육관은 지하 1층과 지상 3층, 연면적...   \n",
              "3  [BOS] 수영장 6개 레인과 어린이풀장, 다목적실(에어로빅, 요가 등), 체력단련...   \n",
              "4                   [BOS] 첫 번째로 개관되는 시설은 헬스장이다 [EOS]   \n",
              "\n",
              "                                        index_tokens  length  \n",
              "0  [40001, 7317, 6662, 8164, 10033, 3128, 3191, 6...      16  \n",
              "1  [40001, 4460, 1053, 3522, 34404, 4121, 1385, 5...      36  \n",
              "2  [40001, 1152, 3128, 12119, 6662, 8164, 10033, ...      30  \n",
              "3  [40001, 22938, 660, 484, 1935, 3237, 1908, 582...      57  \n",
              "4  [40001, 1188, 8647, 7082, 990, 13830, 23585, 4...      10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e51e175-e317-4a2b-be24-b8f200a6bee5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>index_tokens</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[BOS] 익산시 서부권역 다목적 체육관이 내달 개관을 앞두고 막바지 개관 준비가 ...</td>\n",
              "      <td>[40001, 7317, 6662, 8164, 10033, 3128, 3191, 6...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[BOS] 시에 따르면 시민들의 건강증진과 삶의 질 향상을 위한 생활체육 인프라 확...</td>\n",
              "      <td>[40001, 4460, 1053, 3522, 34404, 4121, 1385, 5...</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[BOS] 전문 체육시설인 서부권역 다목적 체육관은 지하 1층과 지상 3층, 연면적...</td>\n",
              "      <td>[40001, 1152, 3128, 12119, 6662, 8164, 10033, ...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[BOS] 수영장 6개 레인과 어린이풀장, 다목적실(에어로빅, 요가 등), 체력단련...</td>\n",
              "      <td>[40001, 22938, 660, 484, 1935, 3237, 1908, 582...</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[BOS] 첫 번째로 개관되는 시설은 헬스장이다 [EOS]</td>\n",
              "      <td>[40001, 1188, 8647, 7082, 990, 13830, 23585, 4...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e51e175-e317-4a2b-be24-b8f200a6bee5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e51e175-e317-4a2b-be24-b8f200a6bee5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e51e175-e317-4a2b-be24-b8f200a6bee5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# index id\n",
        "def index_tokens(sentence, tokenizer):\n",
        "  return tokenizer.encode(sentence).ids\n",
        "\n",
        "def get_special_tokens(x):\n",
        "  return '[BOS] ' + x + ' [EOS]'\n",
        "\n",
        "def length(x):\n",
        "  return len(x)\n",
        "\n",
        "df['sentence'] = df.sentence.apply(get_special_tokens)\n",
        "df['index_tokens'] = df.sentence.apply(lambda x : index_tokens(x, bpe_tokenizer))\n",
        "df['length'] = df.index_tokens.apply(length)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index = df.length.value_counts().sort_index().index\n",
        "value = df.length.value_counts().sort_index().values\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(index, value)\n",
        "plt.ylim([0,45000])\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('count')"
      ],
      "metadata": {
        "id": "AB936iubnnvP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1c3871dc-39b1-48d9-c839-b6baa344e2ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'count')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gWistdjLVO12"
      },
      "outputs": [],
      "source": [
        "# position id\n",
        "def position_tokens(token_list, max_length):\n",
        "  position = [i for i in range(max_length)]\n",
        "  return position\n",
        "\n",
        "def get_pad(x, max_length, tokenizer):\n",
        "  if len(x) < max_length:\n",
        "    return x + tokenizer.encode('[PAD]').ids*(max_length-len(x))\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "def target_processing(x, tokenizer):\n",
        "  return x[1:] + tokenizer.encode('[PAD]').ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "868S_b5svIzX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, data, max_length, tokenizer):\n",
        "      self.GPT_data = data.loc[(data.length >= 15) & (data.length <= max_length)]\n",
        "      self.token = self.GPT_data.index_tokens.to_list()\n",
        "      self.token_ids = [get_pad(x, max_length, tokenizer) for x in self.token]\n",
        "      self.position_ids = [position_tokens(x, max_length) for x in self.token]\n",
        "      self.label = [target_processing(x, tokenizer) for x in self.token_ids]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.token_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return [self.token_ids[idx],   # 실제 token id  \n",
        "              self.position_ids[idx],   # 위치 값\n",
        "              self.label[idx]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M1cQrNtYvI1t"
      },
      "outputs": [],
      "source": [
        "gpt_data = GPTDataset(df, 150, bpe_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(gpt_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dSpRA4ZL32S",
        "outputId": "1622e1ba-7424-42a6-bcff-51f9d7d0b12b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80469"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5lvN6hy2Ayv"
      },
      "source": [
        "# dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bfN-HXuJ2DCm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "  token_id = torch.tensor([b[0] for b in batch])\n",
        "  position_ids =torch.tensor([b[1] for b in batch])\n",
        "  label = torch.tensor([b[2] for b in batch])\n",
        "  return  token_id, position_ids, label\n",
        "\n",
        "input_dataloader = DataLoader(gpt_data, collate_fn=collate_fn, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cMYjejUfCQmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9525d11e-ec63-4c2f-9239-25ebbd010740"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[40001,  7317,  6662,  ..., 40002, 40002, 40002],\n",
              "         [40001,  4460,  1053,  ..., 40002, 40002, 40002],\n",
              "         [40001,  1152,  3128,  ..., 40002, 40002, 40002],\n",
              "         ...,\n",
              "         [40001,  2538,  3540,  ..., 40002, 40002, 40002],\n",
              "         [40001, 10835, 34318,  ..., 40002, 40002, 40002],\n",
              "         [40001,  1683,  9179,  ..., 40002, 40002, 40002]]),\n",
              " tensor([[  0,   1,   2,  ..., 147, 148, 149],\n",
              "         [  0,   1,   2,  ..., 147, 148, 149],\n",
              "         [  0,   1,   2,  ..., 147, 148, 149],\n",
              "         ...,\n",
              "         [  0,   1,   2,  ..., 147, 148, 149],\n",
              "         [  0,   1,   2,  ..., 147, 148, 149],\n",
              "         [  0,   1,   2,  ..., 147, 148, 149]]),\n",
              " tensor([[ 7317,  6662,  8164,  ..., 40002, 40002, 40002],\n",
              "         [ 4460,  1053,  3522,  ..., 40002, 40002, 40002],\n",
              "         [ 1152,  3128, 12119,  ..., 40002, 40002, 40002],\n",
              "         ...,\n",
              "         [ 2538,  3540, 10835,  ..., 40002, 40002, 40002],\n",
              "         [10835, 34318,  3570,  ..., 40002, 40002, 40002],\n",
              "         [ 1683,  9179, 24614,  ..., 40002, 40002, 40002]]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "next(iter(input_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "8WfV5A68noA7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxUoJVqUo7H-"
      },
      "source": [
        "## scaled dot product\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class scaled_dot_product(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(scaled_dot_product, self).__init__()\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, query, key, value, mask, masked):\n",
        "    key_tr = torch.transpose(key, 2, 3)\n",
        "    dk = torch.tensor(query.size()[-1])\n",
        "    outputs = (query @ key_tr) / dk.sqrt()\n",
        "\n",
        "    if mask is not None:\n",
        "      outputs = outputs.masked_fill(mask == 0, -2**30)\n",
        "\n",
        "    if masked:\n",
        "      mask1 = torch.ones_like(outputs[:,:,:])\n",
        "      mask1 = torch.triu(mask1, diagonal=1)\n",
        "      mask1 = mask1*(-2**30)\n",
        "      padding = torch.ones_like(mask1)\n",
        "      padding = torch.tril(padding)\n",
        "      outputs = torch.where(padding==1, outputs, mask1)\n",
        "\n",
        "    attention_map = self.softmax(outputs)\n",
        "    scaled_dp = (attention_map @ value)\n",
        "    return scaled_dp, attention_map"
      ],
      "metadata": {
        "id": "lK1SW9AVomJa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## multihead attention"
      ],
      "metadata": {
        "id": "5KGz8Gv_JHCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class multihead_attention(nn.Module):\n",
        "  def __init__(self, embedding_dims, model_dims, num_heads):\n",
        "    super(multihead_attention, self).__init__()\n",
        "\n",
        "    self.num_heads = num_heads\n",
        "    self.linear_q = nn.Linear(embedding_dims, model_dims)\n",
        "    self.linear_k = nn.Linear(embedding_dims, model_dims)\n",
        "    self.linear_v = nn.Linear(embedding_dims, model_dims)\n",
        "    self.linear_output = nn.Linear(model_dims, model_dims)\n",
        "    self.attention = scaled_dot_product()\n",
        "\n",
        "  def split(self, tensor):\n",
        "    batch_size, sequence_length, d_model = tensor.size()\n",
        "\n",
        "    d_tensor = d_model // self.num_heads\n",
        "    tensor = tensor.view(batch_size, sequence_length, self.num_heads, d_tensor).transpose(1, 2)\n",
        "    return tensor\n",
        "\n",
        "  def cat(self, tensor):\n",
        "    batch_size, self.num_heads, sequence_length, d_tensor = tensor.size()\n",
        "    d_model = self.num_heads * d_tensor\n",
        "\n",
        "    tensor = tensor.transpose(1, 2).contiguous().view(batch_size, sequence_length, d_model)\n",
        "    return tensor\n",
        "\n",
        "  def forward(self, query, key, value, mask, masked):\n",
        "    query1 = self.linear_q(query)\n",
        "    key1 = self.linear_k(key)\n",
        "    value1 = self.linear_v(value)\n",
        "\n",
        "    query_split = self.split(query1)\n",
        "    key_split = self.split(key1)\n",
        "    value_split = self.split(value1)\n",
        "\n",
        "    multihead_attn, attn_map = self.attention(query_split, key_split, value_split, mask, masked)\n",
        "    attn_outputs1 = self.cat(multihead_attn)\n",
        "    attn_outputs2 = self.linear_output(attn_outputs1)\n",
        "    return attn_outputs2"
      ],
      "metadata": {
        "id": "UWEWQs2iqNrs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## feed forward "
      ],
      "metadata": {
        "id": "7kyWOQfjKVuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class feed_forward(nn.Module):\n",
        "  def __init__(self, model_dims, ff_dims):\n",
        "    super(feed_forward, self).__init__()\n",
        "    self.dropout_p = 0.1\n",
        "    self.linear_inner = nn.Linear(model_dims, ff_dims)\n",
        "    self.linear_outer = nn.Linear(ff_dims, model_dims)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=self.dropout_p)\n",
        "\n",
        "  def forward(self, input):\n",
        "    output1 = self.linear_inner(input)\n",
        "    output2 = self.relu(output1)\n",
        "    output3 = self.dropout(output2)\n",
        "    output4 = self.linear_outer(output3)\n",
        "    return output4\n"
      ],
      "metadata": {
        "id": "JfXcuhGTyX4o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## layer norm"
      ],
      "metadata": {
        "id": "tdAGlhFrKYNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class layer_norm(nn.Module):\n",
        "  def __init__(self, model_dims, eps=1e-6):\n",
        "    super(layer_norm, self).__init__()\n",
        "    self.layernorm = nn.LayerNorm(model_dims)\n",
        "\n",
        "  def forward(self, input):\n",
        "    output = self.layernorm(input)\n",
        "    return output"
      ],
      "metadata": {
        "id": "nwI6jVfIz35u"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sublayer connection"
      ],
      "metadata": {
        "id": "I3Q-9-uLKbED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class sublayer_connection(nn.Module):\n",
        "  def __init__(self, model_dims, dropout_p):\n",
        "    super(sublayer_connection, self).__init__()\n",
        "    self.layernorm = layer_norm(model_dims)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self, input, output):\n",
        "    outputs = self.layernorm(input + self.dropout(output))\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "XXNCKoma0kK0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## decoder module"
      ],
      "metadata": {
        "id": "H5BrfXz8KflN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class decoder_module(nn.Module):\n",
        "  def __init__(self, model_dims, ff_dims, dropout_p, embedding_dims, num_heads):\n",
        "    super(decoder_module, self).__init__()\n",
        "    self.multiheadattention_de = multihead_attention(embedding_dims, model_dims, num_heads)\n",
        "    self.feedforward = feed_forward(model_dims, ff_dims)\n",
        "    self.sublayerconnection1 = sublayer_connection(model_dims, dropout_p)\n",
        "    self.sublayerconnection2 = sublayer_connection(model_dims, dropout_p)\n",
        "\n",
        "  def forward(self, decoder_inputs, mask):\n",
        "    masked_multihead_attn = self.sublayerconnection1(decoder_inputs, self.multiheadattention_de(decoder_inputs, decoder_inputs, decoder_inputs, mask, masked=True)) # self attention \n",
        "    outputs1 = self.sublayerconnection2(masked_multihead_attn, self.feedforward(masked_multihead_attn))\n",
        "    return outputs1"
      ],
      "metadata": {
        "id": "mnchGzQdE7g4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## decoder"
      ],
      "metadata": {
        "id": "YigATPIoKjVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class decoder(nn.Module):\n",
        "  def __init__(self, model_dims, ff_dims, num_heads, num_layers, embedding_dims, len_vocab, dropout_p, max_length):\n",
        "    super(decoder, self).__init__()\n",
        "    self.embedding_token = nn.Embedding(len_vocab, embedding_dims)\n",
        "    self.embedding_position = nn.Embedding(max_length, embedding_dims)\n",
        "    self.last_linear = nn.Linear(model_dims, len_vocab)\n",
        "    self.decoder_layer = nn.ModuleList([decoder_module(model_dims = model_dims,\n",
        "                                                       ff_dims = ff_dims,\n",
        "                                                       num_heads = num_heads,\n",
        "                                                       dropout_p=dropout_p,\n",
        "                                                       embedding_dims = embedding_dims)\n",
        "                                        for _ in range(num_layers)])\n",
        "    \n",
        "  def forward(self, decoder_inputs, position, mask):\n",
        "    decoder_embedding = self.embedding_token(decoder_inputs) + self.embedding_position(position)\n",
        "    outputs = decoder_embedding\n",
        "    for layer in self.decoder_layer:\n",
        "      outputs = layer(outputs, mask)\n",
        "    outputs1 = self.last_linear(outputs)\n",
        "    return outputs1"
      ],
      "metadata": {
        "id": "3mSQplp-H7Pu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT"
      ],
      "metadata": {
        "id": "KtzSfE8LKlJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "  def __init__(self, model_dims, ff_dims, num_heads, num_layers, embedding_dims, len_vocab, dropout_p, src_pad_idx, max_length):\n",
        "    super(GPT, self).__init__()\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "    self.decoder = decoder(model_dims, ff_dims, num_heads, num_layers, embedding_dims, len_vocab, dropout_p, max_length)\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, decoder_inputs, position):\n",
        "    decoder_mask = self.make_pad_mask(decoder_inputs, decoder_inputs)\n",
        "    decoder_outputs = self.decoder(decoder_inputs, position, decoder_mask)\n",
        "    return decoder_outputs\n",
        "\n",
        "  def make_pad_mask(self,q,k):\n",
        "    len_q,len_k = q.size(1),k.size(1)\n",
        "    k = k.ne(self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    k = k.repeat(1,1,len_q,1)\n",
        "    q = q.ne(self.src_pad_idx).unsqueeze(1).unsqueeze(3)\n",
        "    q = q.repeat(1,1,1,len_k)\n",
        "    mask = k & q\n",
        "    return mask\n"
      ],
      "metadata": {
        "id": "QgpUOfDxKovk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPAkUkwfSLPn"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7FqkyJ5OFW0",
        "outputId": "cb8ccf57-8d32-494f-9c0b-2fda09b28661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tbehpVb2O1hz"
      },
      "outputs": [],
      "source": [
        "# model_dims, ff_dims, num_heads, num_layers, embedding_dims, len_vocab, dropout_p, src_pad_idx, max_length\n",
        "gpt_model = GPT(512, 1024, 8, 6, 512, 40000+4, 0.1, 40002, 150).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EDONzrCHSXBS"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "lr = 0.0001\n",
        "optimizer = torch.optim.Adam(gpt_model.parameters(), lr=lr, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=40002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EWXUpwePSXBS"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, dataloader):\n",
        "  losses = [] \n",
        "  for i, data in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    token_ids, position_ids, label = data\n",
        "\n",
        "    token_ids = token_ids.to(device)\n",
        "    position_ids = position_ids.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    gpt_logits = model(token_ids, position_ids)\n",
        "    loss = criterion(gpt_logits.transpose(1,2), label)\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "  return sum(losses) / len(losses)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4gq79-GESXBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdaed0d7-aec1-4840-dee5-b662dd9be22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch =  0  avg_loss =  8.44289943020102\n",
            "epoch =  1  avg_loss =  8.392536951865164\n",
            "epoch =  2  avg_loss =  8.449463051972286\n",
            "epoch =  3  avg_loss =  8.334182672329973\n",
            "epoch =  4  avg_loss =  8.126748457959822\n"
          ]
        }
      ],
      "source": [
        "for i in range(epochs):\n",
        "  avg_loss = train(gpt_model, optimizer, criterion, input_dataloader)\n",
        "  print('epoch = ', i, ' avg_loss = ', avg_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SzoXndEcJjEj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}